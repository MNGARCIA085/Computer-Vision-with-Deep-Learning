{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c62ea15-803e-42c7-b705-536f08bbdc95",
   "metadata": {},
   "source": [
    "## PREp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16bf5f5-6832-4e7d-954c-a927afb085a9",
   "metadata": {},
   "source": [
    "TABLE OF CONTYENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e8474c-7e4a-4b64-8292-3a34d8c4cef3",
   "metadata": {},
   "source": [
    "INTRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b65c09-6f8f-4256-a048-bf12daaf31d8",
   "metadata": {},
   "source": [
    "SERTUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c348de44-4d84-4106-8ec2-d37e2a1e1dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:31:17.623114: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-21 17:31:17.623362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-21 17:31:17.769488: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-21 17:31:18.074281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-21 17:31:20.190336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102384d7-8280-4a95-833b-501d2a5be7ec",
   "metadata": {},
   "source": [
    "Generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc875f69-0b3a-4a44-9e0c-5bea4b31b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "img_dir = \"shape_dataset/images\"\n",
    "ann_dir = \"shape_dataset/annotations\"\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(ann_dir, exist_ok=True)\n",
    "\n",
    "# Image and shape parameters\n",
    "img_size = 64\n",
    "shape_size = 10\n",
    "num_images = 50  # Number of images to generate\n",
    "\n",
    "# Function to create bounding box XML\n",
    "def create_voc_xml(filename, width, height, bbox, shape_name, folder=\"images\"):\n",
    "    annotation = ET.Element(\"annotation\")\n",
    "    ET.SubElement(annotation, \"folder\").text = folder\n",
    "    ET.SubElement(annotation, \"filename\").text = filename\n",
    "    ET.SubElement(annotation, \"path\").text = os.path.join(folder, filename)\n",
    "\n",
    "    size = ET.SubElement(annotation, \"size\")\n",
    "    ET.SubElement(size, \"width\").text = str(width)\n",
    "    ET.SubElement(size, \"height\").text = str(height)\n",
    "    ET.SubElement(size, \"depth\").text = \"3\"\n",
    "\n",
    "    ET.SubElement(annotation, \"segmented\").text = \"0\"\n",
    "\n",
    "    obj = ET.SubElement(annotation, \"object\")\n",
    "    ET.SubElement(obj, \"name\").text = shape_name\n",
    "    ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
    "    ET.SubElement(obj, \"truncated\").text = \"0\"\n",
    "    ET.SubElement(obj, \"difficult\").text = \"0\"\n",
    "\n",
    "    bndbox = ET.SubElement(obj, \"bndbox\")\n",
    "    ET.SubElement(bndbox, \"xmin\").text = str(bbox[0])\n",
    "    ET.SubElement(bndbox, \"ymin\").text = str(bbox[1])\n",
    "    ET.SubElement(bndbox, \"xmax\").text = str(bbox[2])\n",
    "    ET.SubElement(bndbox, \"ymax\").text = str(bbox[3])\n",
    "\n",
    "    return ET.ElementTree(annotation)\n",
    "\n",
    "# Function to draw shapes (circle or square) and return the bounding box\n",
    "def draw_shape(img_size, shape_type=\"square\"):\n",
    "    shape_size = 10\n",
    "    img = Image.new(\"RGB\", (img_size, img_size), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    x, y = random.randint(shape_size, img_size - shape_size), random.randint(shape_size, img_size - shape_size)\n",
    "    xmin, ymin = x - shape_size, y - shape_size\n",
    "    xmax, ymax = x + shape_size, y + shape_size\n",
    "\n",
    "    if shape_type == \"square\":\n",
    "        draw.rectangle([xmin, ymin, xmax, ymax], fill=(255, 0, 0))\n",
    "    elif shape_type == \"circle\":\n",
    "        draw.ellipse([xmin, ymin, xmax, ymax], fill=(0, 0, 255))\n",
    "\n",
    "    return img, (xmin, ymin, xmax, ymax), shape_type\n",
    "\n",
    "# Generate images and annotations\n",
    "for i in range(num_images):\n",
    "    shape_type = random.choice([\"square\", \"circle\"])\n",
    "    img, bbox, shape_name = draw_shape(img_size, shape_type)\n",
    "    img_filename = f\"{i:04d}.png\"\n",
    "    img.save(os.path.join(img_dir, img_filename))\n",
    "\n",
    "    xml_filename = f\"{i:04d}.xml\"\n",
    "    tree = create_voc_xml(img_filename, img_size, img_size, bbox, shape_name)\n",
    "    tree.write(os.path.join(ann_dir, xml_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874274f9-60f5-4dc5-a52d-6962a4c0b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noe -> generates only one object per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bbc1dc0-24ff-4558-81fe-e35a892241e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to draw bounding box on an image for display\n",
    "def draw_bbox(image_path, xml_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    bndbox = root.find(\".//bndbox\")\n",
    "    box = [int(bndbox.find(tag).text) for tag in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]]\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle(box, outline=\"green\", width=2)\n",
    "    return img\n",
    "\n",
    "# Display a few images with bounding boxes\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i, fname in enumerate(sorted(os.listdir(img_dir))[:5]):\n",
    "    img_path = os.path.join(img_dir, fname)\n",
    "    xml_path = os.path.join(ann_dir, fname.replace(\".png\", \".xml\"))\n",
    "    img_with_bbox = draw_bbox(img_path, xml_path)\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img_with_bbox)\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a13630-14a7-40f6-aadd-519b7d90d74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000.png  0007.png  0014.png  0021.png\t0028.png  0035.png  0042.png  0049.png\n",
      "0001.png  0008.png  0015.png  0022.png\t0029.png  0036.png  0043.png\n",
      "0002.png  0009.png  0016.png  0023.png\t0030.png  0037.png  0044.png\n",
      "0003.png  0010.png  0017.png  0024.png\t0031.png  0038.png  0045.png\n",
      "0004.png  0011.png  0018.png  0025.png\t0032.png  0039.png  0046.png\n",
      "0005.png  0012.png  0019.png  0026.png\t0033.png  0040.png  0047.png\n",
      "0006.png  0013.png  0020.png  0027.png\t0034.png  0041.png  0048.png\n"
     ]
    }
   ],
   "source": [
    "!ls shape_dataset/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9950480-081c-4038-81ba-b6f68b2c79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an image\n",
    "image_path = img_dir + \"/0000.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733d4ab-0c8e-4575-bdb2-177331f0a0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6dbdf-6530-4edd-8673-2b88a9aabcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae51b6de-579f-4d6e-8ded-8806cb5e9aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000.xml  0007.xml  0014.xml  0021.xml\t0028.xml  0035.xml  0042.xml  0049.xml\n",
      "0001.xml  0008.xml  0015.xml  0022.xml\t0029.xml  0036.xml  0043.xml\n",
      "0002.xml  0009.xml  0016.xml  0023.xml\t0030.xml  0037.xml  0044.xml\n",
      "0003.xml  0010.xml  0017.xml  0024.xml\t0031.xml  0038.xml  0045.xml\n",
      "0004.xml  0011.xml  0018.xml  0025.xml\t0032.xml  0039.xml  0046.xml\n",
      "0005.xml  0012.xml  0019.xml  0026.xml\t0033.xml  0040.xml  0047.xml\n",
      "0006.xml  0013.xml  0020.xml  0027.xml\t0034.xml  0041.xml  0048.xml\n"
     ]
    }
   ],
   "source": [
    "!ls shape_dataset/annotations # are xmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec7e86b8-dcfe-473e-a515-d77838273986",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path = ann_dir + \"/0000.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb0a6d2-06ab-4e49-8da5-32fbe909065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<annotation><folder>images</folder><filename>0000.png</filename><path>images/0000.png</path><size><width>64</width><height>64</height><depth>3</depth></size><segmented>0</segmented><object><name>circle</name><pose>Unspecified</pose><truncated>0</truncated><difficult>0</difficult><bndbox><xmin>34</xmin><ymin>42</ymin><xmax>54</xmax><ymax>62</ymax></bndbox></object></annotation>\n"
     ]
    }
   ],
   "source": [
    "with open(ann_path, 'r') as file:\n",
    "    print(file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ef687f9-92f0-42c9-9ad0-ce9bab71077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" ?>\n",
      "<annotation>\n",
      "\t<folder>images</folder>\n",
      "\t<filename>0000.png</filename>\n",
      "\t<path>images/0000.png</path>\n",
      "\t<size>\n",
      "\t\t<width>64</width>\n",
      "\t\t<height>64</height>\n",
      "\t\t<depth>3</depth>\n",
      "\t</size>\n",
      "\t<segmented>0</segmented>\n",
      "\t<object>\n",
      "\t\t<name>circle</name>\n",
      "\t\t<pose>Unspecified</pose>\n",
      "\t\t<truncated>0</truncated>\n",
      "\t\t<difficult>0</difficult>\n",
      "\t\t<bndbox>\n",
      "\t\t\t<xmin>34</xmin>\n",
      "\t\t\t<ymin>42</ymin>\n",
      "\t\t\t<xmax>54</xmax>\n",
      "\t\t\t<ymax>62</ymax>\n",
      "\t\t</bndbox>\n",
      "\t</object>\n",
      "</annotation>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xml.dom.minidom\n",
    "\n",
    "with open(ann_path, 'r') as file:\n",
    "    xml_string = file.read()\n",
    "\n",
    "# Parse and pretty-print\n",
    "dom = xml.dom.minidom.parseString(xml_string)\n",
    "pretty_xml = dom.toprettyxml()\n",
    "\n",
    "print(pretty_xml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75c28f61-421b-4f95-805f-d2cbb0ccbcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: circle, BBox: (34, 42, 54, 62)\n"
     ]
    }
   ],
   "source": [
    "# Extract object annotations\n",
    "for obj in root.findall(\"object\"):\n",
    "    name = obj.find(\"name\").text\n",
    "    bndbox = obj.find(\"bndbox\")\n",
    "    xmin = int(bndbox.find(\"xmin\").text)\n",
    "    ymin = int(bndbox.find(\"ymin\").text)\n",
    "    xmax = int(bndbox.find(\"xmax\").text)\n",
    "    ymax = int(bndbox.find(\"ymax\").text)\n",
    "    \n",
    "    print(f\"Object: {name}, BBox: ({xmin}, {ymin}, {xmax}, {ymax})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d734c-3617-485a-8f35-da7365c9d927",
   "metadata": {},
   "source": [
    "## Imahe pre-processing\n",
    "\n",
    "- Read\n",
    "- Decode\n",
    "- Cast\n",
    "- Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a8092ca-f1a2-48a5-8958-2734948c5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = image_path\n",
    "\n",
    "img = tf.io.read_file(img_path)\n",
    "img = tf.image.decode_png(img, channels=3)\n",
    "\n",
    "# cast and normalizes to [0, 1] if the original image is an integer type (whcih it is in our case)\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "906b9a74-bce0-43c2-944d-1540fce18c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb8a55-6517-4fae-b234-d75023fc365b",
   "metadata": {},
   "source": [
    "## Annotation pre-processing\n",
    "\n",
    "We need to parse the XML.\n",
    "\n",
    "- Identify the object class (e.g., square, circle) and encode it numerically.\n",
    "- Extract the coordinates of the bounding box.\n",
    "- Normalize the bounding box coordinates to the [0, 1] range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b628bb2b-ab1b-40a9-9d03-c270d5cc35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(ann_path)\n",
    "root = tree.getroot()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "963b8bde-bf6f-4c3b-a033-9a77499211a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = root.find(\".//name\").text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b82ff720-83ba-4f69-a0bf-bed40d236a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "label = 0 if label == \"square\" else 1 # square=0, circle=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "626fc65f-1c74-4598-961b-94793d0abac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'bndbox' at 0x7c345804f470>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox = root.find(\".//bndbox\")\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "314ae16a-b9b2-4c95-97a6-d33ba5950936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 42, 54, 62)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmin = int(bbox.find(\"xmin\").text)\n",
    "ymin = int(bbox.find(\"ymin\").text)\n",
    "xmax = int(bbox.find(\"xmax\").text)\n",
    "ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bd0bb96-b3df-4454-846a-501c38f4a3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.53125, 0.65625, 0.84375, 0.96875]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64 is the img. size\n",
    "bbox_norm = [xmin / 64, ymin / 64, xmax / 64, ymax / 64]\n",
    "bbox_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86cf99ae-5240-44ff-ab8d-d11cb8a3e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in one function\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    label = root.find(\".//name\").text\n",
    "    label = 0 if label == \"square\" else 1  # square=0, circle=1\n",
    "\n",
    "    bbox = root.find(\".//bndbox\")\n",
    "    xmin = int(bbox.find(\"xmin\").text)\n",
    "    ymin = int(bbox.find(\"ymin\").text)\n",
    "    xmax = int(bbox.find(\"xmax\").text)\n",
    "    ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "    # Normalize bbox coordinates to [0, 1]\n",
    "    bbox_norm = [xmin / 64, ymin / 64, xmax / 64, ymax / 64]\n",
    "    return label, bbox_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885da8b-a3a4-4a89-b0ae-b79ea0cf4fec",
   "metadata": {},
   "source": [
    "## Load an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ecd6a78-5216-44e2-b6a1-7af09191b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_example(img_path, label, bbox):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # scale [0,1] the image\n",
    "    return img, {\"label\": label, \"bbox\": bbox}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdda6a5d-1723-4c7d-b439-390117d24b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label , bbox = parse_xml(ann_path)\n",
    "\n",
    "img, ann = load_example(img_path, label, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a391f14-55b6-47d7-b54a-12dc15e3d4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1, 'bbox': [0.53125, 0.65625, 0.84375, 0.96875]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9463c90-284e-41c1-8abc-5931fc49c6aa",
   "metadata": {},
   "source": [
    "## TF DATASEWST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b861eb6-e9c0-4887-969b-112ad5da36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code builds a list of labeled image samples with their corresponding bounding boxes,\n",
    "\n",
    "samples = []\n",
    "for fname in sorted(os.listdir(img_dir)):\n",
    "    if fname.endswith(\".png\"):\n",
    "        img_path = os.path.join(img_dir, fname)                         # Path to image\n",
    "        xml_path = os.path.join(ann_dir, fname.replace(\".png\", \".xml\")) # Matching annotation path\n",
    "        label, bbox = parse_xml(xml_path)                               # Extract label and bbox from XML\n",
    "        samples.append((img_path, label, bbox))                         # Save as a tuple\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecae0c38-1664-4fa3-abdf-b0005ca47ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shape_dataset/images/0015.png', 1, [0.21875, 0.328125, 0.53125, 0.640625]),\n",
       " ('shape_dataset/images/0001.png', 0, [0.03125, 0.34375, 0.34375, 0.65625]),\n",
       " ('shape_dataset/images/0010.png',\n",
       "  0,\n",
       "  [0.140625, 0.484375, 0.453125, 0.796875]),\n",
       " ('shape_dataset/images/0034.png', 0, [0.625, 0.078125, 0.9375, 0.390625]),\n",
       " ('shape_dataset/images/0005.png',\n",
       "  0,\n",
       "  [0.203125, 0.296875, 0.515625, 0.609375]),\n",
       " ('shape_dataset/images/0004.png', 1, [0.078125, 0.59375, 0.390625, 0.90625]),\n",
       " ('shape_dataset/images/0000.png', 1, [0.53125, 0.65625, 0.84375, 0.96875])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9babc811-f66e-4e57-9ced-0bfa05b02c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "random.shuffle(samples)\n",
    "split_idx = int(0.8 * len(samples))\n",
    "train_samples = samples[:split_idx]\n",
    "val_samples = samples[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "877b0c45-97a5-4d85-a72f-1ab4c36b9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(samples, batch_size=4, training=True):\n",
    "    img_paths, labels, bboxes = zip(*samples)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((list(img_paths), list(labels), list(bboxes)))\n",
    "    ds = ds.map(lambda x, y, z: load_example(x, y, z))\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.shuffle(100)\n",
    "        \n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8d7e4a92-7595-49c3-b391-3b64499eec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_samples, batch_size=1)\n",
    "val_ds = make_dataset(val_samples, batch_size=1, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985cd7d4-050c-4903-8a88-15802d4b57de",
   "metadata": {},
   "source": [
    "train_ds and val_ds are tf.data.Dataset objects.\n",
    "\n",
    "Each item is a tuple:\n",
    "(image, {\"label\": shape_class, \"bbox\": normalized_box})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cedcfd10-91fe-4b24-bff8-11bb8a31caa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (1, 64, 64, 3)\n",
      "targets: {'label': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, 'bbox': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.5625  , 0.359375, 0.875   , 0.671875]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for images, targets in train_ds.take(1):\n",
    "    print(\"Images:\", images.shape)\n",
    "    print(\"targets:\", targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c284595-e3d6-4f17-b22f-7785edf49eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (1, 64, 64, 3)\n",
      "Labels: tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "BBoxes: tf.Tensor([[0.6875   0.390625 1.       0.703125]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for images, targets in train_ds.take(1):\n",
    "    print(\"Images:\", images.shape)\n",
    "    print(\"Labels:\", targets[\"label\"])\n",
    "    print(\"BBoxes:\", targets[\"bbox\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81692da-c1c7-46ad-b3cd-6e74bc893faf",
   "metadata": {},
   "source": [
    "If each item muste be:\n",
    "\n",
    "(image_tensor, {\"classification\": int_label, \"bounding_box\": [xmin, ymin, xmax, ymax]})\n",
    "\n",
    "\n",
    "\n",
    "not:\n",
    "\n",
    "(image_tensor, {\"label\": ..., \"bbox\": ...})\n",
    "\n",
    "I can remap keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3aeaed7-5c7b-49d8-a65e-20a8256d7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_keys(img, targets):\n",
    "    return img, {\n",
    "        \"classification\": targets[\"label\"],\n",
    "        \"bounding_box\": targets[\"bbox\"]\n",
    "    }\n",
    "\n",
    "train_ds = train_ds.map(remap_keys)\n",
    "val_ds = val_ds.map(remap_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "981c0b91-47b4-41c5-b7bd-43f66ec1e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (1, 64, 64, 3)\n",
      "targets: {'classification': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, 'bounding_box': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.234375, 0.265625, 0.546875, 0.578125]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for images, targets in train_ds.take(1):\n",
    "    print(\"Images:\", images.shape)\n",
    "    print(\"targets:\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35dd3af8-3c57-4d4a-b439-3b2945e93fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (1, 64, 64, 3)\n",
      "Classification: tf.Tensor([1], shape=(1,), dtype=int32)\n",
      "BBoxes: tf.Tensor([[0.546875 0.28125  0.859375 0.59375 ]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for images, targets in train_ds.take(1):\n",
    "    print(\"Images:\", images.shape)\n",
    "    print(\"Classification:\", targets[\"classification\"])\n",
    "    print(\"BBoxes:\", targets[\"bounding_box\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3cb37-054f-454b-9bd9-06e989227942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
